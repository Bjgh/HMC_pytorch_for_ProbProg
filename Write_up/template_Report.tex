\documentclass[]{report}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage{subfigure}
%%\usepackage{tikz}
%\usepackage{algorithm}
\usepackage{algpseudocode}
%\usepackage{graphicx}
%\usepackage{subfig}
% Title Page
\title{Hamiltonian Monte Carlo}
\author{Bradley Gram-Hansen}


\begin{document}
\maketitle

\begin{abstract}
	These are note on aspects of Hamiltonian monte carlo methods.]
\end{abstract}


\section{Radford Neals intro to HMC MCMC}

\subsection{Metropolis-hastings algorithm}
The Metropolis hastings algorithm is the work horse of Monte Carlo Markov Chain (MCMC) methods, It relies on a simple reject and accept criteria for determining whether or not we should proceed to some next state. If our state is accepted, but does not satisfy the full criteria then a probability is associated with that state, and if that probability exceeds the one sampled from a given cut off, usually determined by sampling from a uniform distribution then it is accepted, else rejected. 

\begin{algorithm}
\caption{Metropolis-Hasting algorithm}
\begin{algorithmic}[1]
	\State  $x^{0} \sim P_{0}(x)$ \Comment{Where $p(x)$ is the proposed initial distribution}
		\For {$s = 0,1,2,\ldots$}
		\State $ x \gets x^{s} $
		\State $ x^{'} \sim Q(x^{'}|x)$
		\State $a = \frac{\tilde{P}(x')Q(x|x')}{\tilde{P}(x)Q(x'|x)}$ \Comment{Acceptance ratio}
		\State $r = min(1, a) $ \Comment{Acceptance condition}
		\State $u \sim  U(0,1)$ 
		\State $x^{s+1} = \begin{cases}
		x' \text{ if $u < r$}\\
		x^{s} \text{ if $u \geq r$}
		\end{cases}$
		\EndFor
\end{algorithmic} 
\end{algorithm}

\subsection{HMC for MCMC}

In a top level view Hamilton Monte Carlo for Monte Carlo Markov Chain (HMC MCMC) is a two step process. In step one we define a Hamiltonian function in terms of the probability distribution from which we wish to sample from. We introduce a position variable, $q$ and momentum variable $p$, where $p$ is an auxiliary variable that typically has a Gaussian distribution.  All $p$'s are assumed independent. 
In step two, the HMC alternates simple updates for the momentum variables with Metropolis updates. This enables us to propose a new state by computing a trajectory according to Hamiltonian dynamics, implemented with the leapfrog method. 
\subsubsection{Prerequisites}
The Hamiltonian of a physical system is defined completely with respect to the position $q$ and $p$ momentum variables, which span the phase space of the system. The Hamiltonian is the Legendre transform of the Lagrangian and gives us the total energy in the system. It is defined as follows: 
\begin{equation}
\label{eq:hamiltonian}
 H(\textbf{q},\textbf{p}) = \sum_{i = 1}^{d}\dot{q}_{l}p_{l} - L(\textbf{q}, \textbf{\.{q}}(\textbf{q}, \textbf{p}))
\end{equation}
where $d$ is the system dimensions, and so the full state space with has $2d$ dimensions.  
Thus, for simplicity, if we set $d = 1$ we can derive the Hamiltonian equations as follows:\begin{equation}
\frac{\partial H}{\partial p} = \dot{q} + p\frac{\partial \dot{q}}{\partial p} - \frac{\partial L}{\partial \dot{q}}\frac{\partial \dot{q}}{\partial p} = \dot{q} \end{equation}
and 
\begin{equation}
\frac{\partial H}{\partial q} = p\frac{\partial \dot{q}}{\partial q} - \frac{\partial L}{\partial q} - \frac{\partial L}{\partial \dot{q}}\frac{\partial \dot{q}}{\partial q} = - \frac{\partial L}{\partial q}= -\dot{p}  \end{equation}
and the process is the same for more than one dimension. 
We can write \ref{eq:hamiltonian}\ more succinctly as:
\begin{equation}
\label{eq:hamreduced}
H(\textbf{q}, \textbf{p})  = K(p) + U(q)
\end{equation}
where $K(p)$ represents our kinetic energy and $U(q)$ is the potential energy.

Within the HMC MCMC framework the ''positions", $q$, are the variables of interest and for each position variable we have to create a fictitious ''momentum", $p$. For compactness let $z = (q,p)$. The potential energy $U(q)$ will be the minus of the log of the probabilty density for the distribution of the position variables we wish to sample, plus \textbf{any} constant that is convenient.  The kinetic energy will represents the dynamics of our variables, for which a popular form of $K(p) = \frac{p^{T} M^{-1} p}{2}$, where $M$ is symmetric, positive definite and typically diagonal. This form of $K(p)$ corresponds to a minus the log probability of the zero mean Gaussian distribution with covariance matrix $M$. For this choice we can write the Hamiltonian equations, for any dimension $d$, as follows:
\begin{align}
\dot{q}_{i} &= \frac{dq_{i}}{dt} = [M^{-1}p]_{i} \\
\dot{p}_{i} &= \frac{dp_{i}}{dt} = -\frac{\partial U}{\partial q_{i}}
\end{align}

To view the Hamiltonian in terms of probabilities, we use the concept of the canonical distribution from Statistical mechanics to construct our pdf. Thus, the distribution that we wish to sample from can be related to the potential energy via the canonical distribution as:
\begin{equation}
\label{eq:canonical}
P(z) = \frac{1}{Z}\exp\left(\frac{-E(z)}{T}\right)
\end{equation}
As the Hamiltonian is just an energy function we may can insert \ref{eq:hamreduced}\ into our canonical distribution \ref{eq:canonical}\, which gives us the joint density:
\begin{equation}
P(q,p) = \frac{1}{Z}\exp(-U(q))\exp(-K(p)  
\end{equation}
where $T = 1$ is fixed. 
Where we characterise the posterior distribution for the model parameters using the potential energy function" \begin{equation}
U(q) = -\log[\pi(q)L(q|D)]
\end{equation}
where $\pi(q)$ is the prior distribution, and $L(q|D)$ is the likelihood, not the Lagrangian, of the given data $D$. 

\subsection{The Algorithm}

\subsubsection{The leapfrog method}
The leapfrog method enables reduced error and allows us to dicretize Hamiltons equations, so that we can implement them numerically. 
We start with a state at $t = 0$ and then evaluate at a subsequent time $t + \epsilon , \hdots, t + n\epsilon$, where $\epsilon$ is the step in which we increase and $n$ is the number of time steps. 

\begin{align}
p_{i}(t + \frac{\epsilon}{2}) &= p_{i}(t) - \left(\frac{\epsilon}{2}\right)\frac{\partial U(q(t))}{\partial q_{i}} \\
q_{i}(t + \epsilon) &= q_{i}(t) + \epsilon\frac{\partial K(p + \frac{\epsilon}{2})}{dp_{i}}\\
p_{i}(t + \epsilon) &= p_{i}(t + \frac{\epsilon}{2}) - \left(\frac{\epsilon}{2}\right)\frac{\partial U}{\partial q_{i}}\\
\end{align}
\footnote{For the usual choice of kinetic energy, we have $\frac{\partial K(p + \frac{\epsilon}{2})}{dp_{i}} = \frac{p_{i}(t + \frac{\epsilon}{2})}{m_{i}}$}

For the leapfrog method the local error, error after one step, is of $\mathcal{O}(\epsilon^{2})$ and a global error, error after simulating for some fixed time interval s, which requires $\frac{s}{\epsilon}$ is $\mathcal{O}(\epsilon^{3})$
\subsubsection{Some initial points of notice}
Neals implementation of the HMC can only be used to sample from continuous distributions on $\mathbb{R}^{d}$ for which a density function can be evaluated.\\
We must be able to compute the partial derivative of the log of the density function. The derivaties must exists at the points at which they are evaluated [\textbf{Automatic differention}]

HMC samples from the canonical distribution for $q$ and $p$. $q$ has the distribution of interest as specified by the potential $U(q)$. 
The distribution of the $p$'s can be chosen by us and are independent of the $q$'s. 
The $p$ components are specified to be independent, with component $p_{i}$ having variance $m_{i}$.
The kinetic energy $K(p) = \sum_{i =1}^{d}\frac{p_{i}^{2}}{2m_{i}}(q(t + \epsilon))
$

\subsubsection{The steps}

\begin{enumerate}
	\item Step 1: Changes only the momentum
	\item Step 2: May change both position and momentum
\end{enumerate}
Both steps leave the canonical distribution of (q,p) invariant, hence the distribution remains invariant.

In \textbf{Step 1} we first draw the $p_{i}$ randomly from their Gaussian distribution independently of the current values of the position values. 

next, in \textbf{Step 2} a Metropolis update is performed, using the Hamiltonian dynamics to propose a new state. Starting with the current state $(q,p)$, Hamiltonian dynamics is simulated for $L$ steps using the leapfrog method, with a stepsize of $\epsilon$. $L$ and $\epsilon$ are parameters of the mnodel that need to be tuned. 

The momentum vairables at the end of this $L$-step trajectory are then negated, giving s proposed state $(q^{*}. p^{*})$. This proposed state is accepted as the next state in the Markov Chain with probability: \begin{equation}
\min[1, \exp(-H(q^{*}, p^{*}) + H(p,q)] = \min[1, \exp(-U(q^{*}) + U(q) - K(p^{*}) + K(p))]
\end{equation} 
If the proposed state is rejected, then the next state is the same as the current state and is counted again when calculating the expected value of some function. 
The negation of the momentum variables at the end of the trajectory makes the Metropolis proposal symmetrical, as needed for the acceptance probability above to be valid. This negation need not be done in practice, since $K(p) = K(-p)$, and the momentum will be replaced before it is used again, in the first step of the next iteration.
\end{document} 