% !TEX root = ../main.tex
\section{Hamiltonian Monte Carlo}
\label{sec:hmc}
In a top level view HMC is a two step process. In step one, we define a Hamiltonian function in terms of the joint probability distribution of the model that we aim to perform inference on and in step two, HMC proposes new states generated via Hamiltonian dynamics for which we apply Metropolis updates. As the proposals are being generated via a physical process, we are able to comprehensively explore our model space \citep{neal2011mcmc}. This is in part due to certain physical properties of the Hamiltonian itself, that make HMC a very powerful, multi-purpose inference algorithm. Adopting the notation from the machine learning literature, we use $\textbf{x} \in \mathbb{R}^{n \times d}$ to represent the parameters of interest, our latent variables, rather than the typical $\mathbf{\theta}$ and $\textbf{q}$ in the HMC literature. Where $n$ represents the number of parameters of interest and $d$ is the dimension of the system.

The Hamiltonian of a physical system is defined completely in terms of the sets of points $(\textbf{x}, \textbf{p})$, the position and momentum variables respectively. These points span what is called the phase space, which formally is defined as the cotangent bundle $T^{*}\mathcal{M}$ of the configuration space $\mathcal{M}$. Simply put, we can imagine the phase space as a manifold that shows us both how our model evolves, with respect to $\textbf{x}$ and $\textbf{p}$ and how it is constrained in regards to the total energy within the system. Where the total energy of the system is given by the Hamiltonian, $H(\textbf{x},\textbf{p})$. The Hamiltonian is the Legendre transform of the Lagrangian and is formally defined as $
H(\textbf{x}, \textbf{p})  = K(\textbf{p}) + U(\textbf{x})$ where $K(\textbf{p})$ represents our kinetic energy and $U(\textbf{x})$ is the potential energy. The Legendre transform is given by $H(\textbf{x},\textbf{p}) = \sum_{i = 1}^{d}\dot{x}_{i}p_{i} - L(\textbf{x}, \textbf{\.{x}}(\textbf{x}, \textbf{p})) $\footnote{The $\dot{x}$ represents that the variable is being differentiated with respect to time.}.  
Thus, for simplicity, if we set $d = 1$, we can derive Hamilton's equations: 
\begin{equation}
\label{eq:hameq1}
\frac{\partial H}{\partial p} = \dot{x} + p\frac{\partial \dot{x}}{\partial p} - \frac{\partial L}{\partial \dot{x}}\frac{\partial \dot{x}}{\partial p} = \dot{x} 
\end{equation}
and 
\begin{equation}
\label{eq:hameq2}
\frac{\partial H}{\partial x} = p\frac{\partial \dot{x}}{\partial x} - \frac{\partial L}{\partial x} - \frac{\partial L}{\partial \dot{x}}\frac{\partial \dot{x}}{\partial x} = - \frac{\partial L}{\partial x}= -\dot{p}  
\end{equation}
from which we can vectorize for higher dimensions. It should be noted that the derivatives for the Lagrangian $L$, come from the Euler-Lagrange equations $\frac{d}{dt}\left(\frac{\partial L}{d\dot{x}}\right) = \frac{\partial L}{dx}$ and the Lagrangian itself, is just a reformulation of Newtonian mechanics.

Within the HMC framework the positions, $\textbf{x}$, are the variables of interest, but in order to simulate Hamiltonian dynamics properly, for each $\textbf{x}$ we must introduce an auxillary momentum variable $\textbf{p}$. But what form should $\textbf{p}$ take? Typically, $\textbf{p}$ is sampled from a normal distribution $\textbf{p} \sim \mathcal{N}(\textbf{0}, \mathds{1})$, although this need not be the case. In HMC, the potential energy $U(\textbf{x})$ represents the negative log joint distribution of the model and is a key component within the algorithm.  The kinetic energy $K(\textbf{p})$, is typically taken to be the mean field approximation, which corresponds directly to the log of a centered Gaussian distribution $K(\textbf{p}) = \frac{\textbf{p}^{T} \textbf{M}^{-1} \textbf{p}}{2}$, where $\textbf{M}$, the mass matrix, is a symmetric, positive definite and typically diagonal matrix. Although, again we need not choose this form of kinetic energy, when adapting HMC for discrete parameters, it is actually more beneficial to use a different kinetic function\citep{nishimura2017discontinuous}. Thus, if we are to use the standard kinetic energy, which we do for all our current models, then Hamilton's equations take the form $
\dot{\textbf{x}} = \frac{d\textbf{x}}{dt} = [\textbf{M}^{-1}\textbf{p}]$ and $ \dot{\textbf{p}} = \frac{d\textbf{p}}{dt} = -\nabla_{\textbf{x}}U(\textbf{x})$.\\
To understand why the potential energy represents the joint, we take inspiration from the canonical distribution found in statistical mechanics
$P(\textbf{x},\textbf{p}) = \frac{1}{Z}\exp\left(\frac{-E(\textbf{x},\textbf{p})}{\kappa_{b}T}\right)$,
where $Z$ is a normalization constant \footnote{This is actually the partition function, which to those familiar with neural nets, will know this as the \textit{softmax} function. }, $E$ represents the total energy of the system, our Hamiltonian, and $\kappa_{b} = T = 1$ are constants that we define to be unit. Substituting the Hamiltonian $H$ into the canonical distribution gives us the joint density of the system, not our model:
\begin{equation}
P(\textbf{x},\textbf{p}) = \frac{1}{Z}\exp(-U(\textbf{x}))\exp(-K(\textbf{p})) 
\end{equation}
It should be noted, that it is not always the case that Hamiltonian is separable, for example see Riemannian HMC \citep{girolami2011riemann}. As this expression is exponentiated and there are no implicit dependencies between the parameters, we can marginalize out the distribution of axillary momentum, leaving us with just the target distribution, the joint density, $P(\textbf{x})  = \exp(-U(\textbf{x}))$. In taking the $\ln$ of this, we find that:
\begin{equation}
U(\textbf{x}) = -\ln P(\textbf{x})
\end{equation} and so the potential is entirely dependent on the form of the joint distribution. However, the expression $P(\textbf{x})$ factorizes further via the product rule,
into the product of a prior $p(\textbf{x})$ for the parameters of interest and a likelihood $p(\textbf{x}|\textbf{y})$ given the observations $\textbf{y}$: \begin{equation}
U(\textbf{x}) = -\log[p(\textbf{x})p(\textbf{x}|\textbf{y})]
\end{equation}

\subsection{The Integrator}

In order to implement HMC correctly we require an integrator that will enable us to solve the Hamilton's equations, equations (\ref{eq:hameq1}-\ref{eq:hameq2}). For an integrator to do this it must be both time reversible and volume preserving, as the flow of phase space is fixed. The time reversibility is due to the fact that no physical system should have a preferred direction of time, if I start at my initial conditions, I should eventually arrive back at those initial conditions. In order to ensure that our integrator is volume preserving, we require our integrator to be symplectic. This means that given a transformation $\textbf{Q} \in Sp(2d, \mathbb{R})$ such that $\textbf{Q}(\textbf{p}_{0}, \textbf{x}_{0}) \mapsto (\textbf{x}, \textbf{p})$, which maps an initial state to some evolved state, for the transformation to preserve Hamilton's equations it must be a canonical transformation. But, this can be only true if given some matrix $J = \left(\begin{array}{cc} \mathbf{0} & \mathbb{I} \\ -\mathbb{I} & \mathbf{0}\end{array}\right)$ the relation $\textbf{Q}^{T}J\textbf{Q} = J$ is satisfied, which is only true if $\textbf{Q}$ is symplectic. This can be proved as follows. If we have a transformation $R = R(\textbf{x})$, then $\dot{R} = \textbf{Q}^{T}J\textbf{Q}\nabla_{\textbf{Q}}H = J\nabla{\textbf{Q}}H$\footnote{We can write $\textbf{z} = (\textbf{x}, \textbf{p})$ and taking the vectorized form of equations (\ref{eq:hameq1} - \ref{eq:hameq2}), in terms of Laplacians, we can succinctly write Hamilton's equations as $\dot{\textbf{z}} = J\nabla_{\textbf{z}}H(\textbf{z})$. }, which is true if and only if $\textbf{Q}^{T}J\textbf{Q} = J$ and thus the transformation is symplectic.

A popular choice within the HMC literature is the Leapfrog integrator, equations (\ref{eq:leapfrog1}-\ref{eq:lf2}). Not only does it satisfy the physical constraints of the model, but it has very small local  $\mathcal{O}(\epsilon^{2})$ and global errors $\mathcal{O}(\epsilon^{3})$ with fast convergence \citep{neal2011mcmc}. Although we shall be using the Leapfrog integrator throughout our current work, it should again be noted that this integrator can take alternative forms, for example see \citep{girolami2011riemann}\citep{nishimura2017discontinuous} and \citep{blanes2012explicit}. The Leapfrog method enables us to generate new proposals given some initial state, that is, if we start with a state at $t = 0$ and then evaluate at a subsequent time $t + \epsilon , \hdots, t + N\epsilon$ we will generate a new state $(\textbf{x}(t + N\epsilon),\textbf{p}(t + N\epsilon))$ which will act as our new proposal. Where $\epsilon$ is the time step by which we increase and $N$ is the total number of time steps.

\begin{align}
\label{eq:leapfrog1}
\textbf{p}(t + \frac{\epsilon}{2}) &= \textbf{p}(t) - \left(\frac{\epsilon}{2}\right) \nabla_\textbf{x}U(\textbf{x}(t)) \\
\textbf{x}(t + \epsilon) &= \textbf{x}(t) + \epsilon \nabla_{\textbf{p}}K(\textbf{p}(t + \frac{\epsilon}{2}))\\
\label{eq:lf2}
\textbf{p}(t + \epsilon) &= \textbf{p}(t + \frac{\epsilon}{2}) - \left(\frac{\epsilon}{2}\right)\nabla_{\textbf{x}} U(\textbf{x}(t+\epsilon))
\end{align}
\subsection{The Algorithm}


Before we provide the full HMC algorithm we shall briefly discuss how the second stage of HMC works, that is the Metropolis step. Starting with the current state $(\textbf{x},\textbf{p})$, Hamiltonian dynamics is simulated for $L$ steps using the Leapfrog integrator, with a step size of $\epsilon$. This generates a new proposed state and in order to decide whether we should accept or reject this proposal, \citep{duane1987hybrid} introduced the following acceptance (Metropolis) proposal:
\begin{multline}
\label{eq:metrop}
\min[1, \exp(-H(\textbf{x}^{*}, \textbf{p}^{*}) + H(\textbf{x}, \textbf{p})] =\\
\min[1, \exp(-U(\textbf{x}{*}) + U(\textbf{x}) - K(\textbf{p}^{*}) + K(\textbf{p}))]
\end{multline}where $ (\textbf{x}^{*}, \textbf{p}^{*})$ is the proposed state and $(\textbf{x}, \textbf{p})$ is the current state. A function that implements a run of the HMC algorithm is given in algorithm \ref{alg:simpHMC}. If the proposed state is rejected, then the next state is the same as the current state and is counted again when calculating the expected value of some posterior. 
Theoretically speaking, in order to ensure that the proposal is symmetric, we should negate the momentum variables at the end of the trajectory, to ensure that the Metropolis proposal is symmetrical, which is needed for the acceptance probability to be valid. However, in practice we do not need to perform this negation since $K(\textbf{p}) = K(-\textbf{p})$ for the Gaussian momentum and after each iteration the momentum will be replaced before it is used again. Hence, we leave it out of algorithm \ref{alg:simpHMC}. The authors issue a note of caution, as the potential is the negative of the log joint, we have equation (\ref{eq:metrop}). However, many implementations of HMC do not take this into account and so the proposal is in some instances defined as equation (\ref{eq:metrop}), but the potential is defined to be the positive of the log joint. Hence the proposal would be invalid. In our implementation, when the Hamiltonians are being computed we are dealing with the negative of the log joint, but during the leapfrog step we are dealing with the positive of the log joint, hence the sign changes in algorithm \ref{alg:simpHMC}.  
\begin{algorithm}
	\caption{\textbf{Continuous Hamiltonian Monte Carlo MCMC}}
	\begin{algorithmic}[1]
		\Procedure{HMC}{$x_{0}$, $\epsilon$, $L$,$U$, $M$}
		\For{$m = 1 \text{ to } M$}
		\State {$ \textbf{p}^{0} \sim \mathcal{N}(0,\mathds{1})$}
		\State {$(\textbf{x}_{0}, \textbf{p}_{0}) \gets (\textbf{x}^{(t)}, \textbf{p}^{(t)})$}
		\State {$\textbf{p}_{0} \gets \textbf{p}_{0} + \frac{\epsilon}{2}\nabla_{\textbf{x}} U(\textbf{x}_{0})$}
		\For{$i = 1 \text{ to } L$}
		\State {$(\hat{\textbf{x}}, \hat{\textbf{p}}) \gets$ Leapfrog($\textbf{x}_{0}, \textbf{p}_{0}, \epsilon$)}
		\EndFor
		\State {$\textbf{p}_{L} \gets \textbf{p}_{L} - \frac{\epsilon}{2}\nabla_{\textbf{x}} U(\textbf{x}_{L})$}
		\State {$\alpha = \min\left\{1, \exp \left\{H(\textbf{x}^{(t)}, \textbf{p}^{(t)}) - H(\hat{\textbf{x}}, \hat{\textbf{p}})\right\}\right\}$}
		\State {$u \sim Uniform(0,1)$}
		\If{ $u < \alpha $}
		\State {\Return $ \textbf{x}^{(t + 1)} \gets \hat{\textbf{x}}$}  \Comment{Accept}
		\Else
		\State {\Return $\textbf{x}^{(t+1)}  \gets \textbf{x}^{t}$} \Comment{Reject}
		\EndIf
		\EndFor
		\State {Leapfrog($\textbf{x}$, $\textbf{p}$, $\epsilon$)} 
		\State {$\textbf{x}_{i} \gets \textbf{x}_{i} + \epsilon \nabla_{\textbf{p}} K(\textbf{p}_{i})$} 
		\State {$\textbf{p}_{i} \gets \textbf{p}_{i-1} + \frac{\epsilon}{2}\nabla_{\textbf{x}}U(\textbf{x}_{i-1})$}
		\State {\Return $\hat{\textbf{x}}$ , $\hat{\textbf{p}}$}
		\EndProcedure
	\end{algorithmic}
   \label{alg:simpHMC} 
\end{algorithm}

The parameters  $\epsilon$ and $L$ within algorithm \ref{alg:simpHMC} are parameters that need to be tuned. Likewise, if the form of the kinetic is taken to be the log of a Gaussian, $\textbf{M}$ becomes another parameter that needs to be tuned correctly. Although, one could use Riemannian HMC \citep{girolami2011riemann} to generate a mass matrix on the fly, which is based on the geometrical properties of the model that you are sampling from.

 
